{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `dev`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import nemo\n",
    "import copy\n",
    "import tqdm\n",
    "import timeit\n",
    "import shutil\n",
    "import pathlib\n",
    "import attrdict\n",
    "import numpy as np\n",
    "\n",
    "from ruamel import yaml\n",
    "from Bio import pairwise2\n",
    "from nemo.collections import asr as nemo_asr\n",
    "from nemo.collections.asr.helpers import post_process_predictions, post_process_transcripts, word_error_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGC_MAP = '~/Downloads/librivox-train-all.json'\n",
    "LOCAL_MAP = [\n",
    "    '/home/stanislavv/data/nemo-librispeech/train_clean_100.json',\n",
    "    '/home/stanislavv/data/nemo-librispeech/train_clean_360.json',\n",
    "    '/home/stanislavv/data/nemo-librispeech/train_other_500.json',\n",
    "]\n",
    "AD_HOC_MAP = '/home/stanislavv/data/librispeech/train-all.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_BASE = pathlib.Path('/home/stanislavv/data/librispeech')\n",
    "\n",
    "NGC_BASE = DATA_BASE / 'ngc'\n",
    "NGC = [\n",
    "    NGC_BASE / 'librivox-dev-clean.json',\n",
    "    NGC_BASE / 'librivox-dev-other.json',\n",
    "    NGC_BASE / 'librivox-test-clean.json',\n",
    "    NGC_BASE / 'librivox-test-other.json',\n",
    "    NGC_BASE / 'librivox-train-all.json',\n",
    "]\n",
    "\n",
    "LOCAL_BASE = DATA_BASE / 'local'\n",
    "LOCAL = [\n",
    "    LOCAL_BASE / 'dev_clean.json',\n",
    "    LOCAL_BASE / 'dev_other.json',\n",
    "    LOCAL_BASE / 'test_clean.json',\n",
    "    LOCAL_BASE / 'test_other.json',\n",
    "    LOCAL_BASE / 'train_all.json',\n",
    "]\n",
    "\n",
    "NEW_LOCAL_BASE = DATA_BASE / 'new-local'\n",
    "NEW_LOCAL = [\n",
    "    NEW_LOCAL_BASE / 'dev-clean.json',\n",
    "    NEW_LOCAL_BASE / 'dev-other.json',\n",
    "    NEW_LOCAL_BASE / 'test-clean.json',\n",
    "    NEW_LOCAL_BASE / 'test-other.json',\n",
    "    NEW_LOCAL_BASE / 'train-all.json',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngc_id(audio_file):\n",
    "    return os.path.basename(audio_file)[:-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap(ngc_map, local_map, new_file):\n",
    "    order = [\n",
    "        get_ngc_id(example['audio_file']) \n",
    "        for example in nemo.collections.asr.parts.manifest.item_iter(str(ngc_map))\n",
    "    ]\n",
    "    \n",
    "    local_id_index = [\n",
    "        (get_ngc_id(example['audio_file']), i)\n",
    "        for i, example in enumerate(nemo.collections.asr.parts.manifest.item_iter(str(local_map)))\n",
    "    ]\n",
    "    \n",
    "    local_id_index_dict = dict(local_id_index)\n",
    "    new_order = [local_id_index_dict[id_] for id_ in order]\n",
    "\n",
    "    lines = []\n",
    "    with open(local_map, 'r') as f:\n",
    "        lines.extend(list(f))\n",
    "    lines = [lines[id_] for id_ in new_order]\n",
    "    \n",
    "    with open(new_file, 'w') as f:\n",
    "        for line in lines:\n",
    "            f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ngc, local, new_local in zip(NGC, LOCAL, NEW_LOCAL):\n",
    "    remap(ngc, local, new_local)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = 'dev-clean'\n",
    "MAP = f'/home/stanislavv/data/libritts/local/{NAME}.json'\n",
    "SAMPLE_RATE = 24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-03-25 02:20:42 deprecated:68] Function ``_get_trainer`` is deprecated. It is going to be removed in the future version.\n"
     ]
    }
   ],
   "source": [
    "runner = nemo.core.NeuralModuleFactory(\n",
    "    placement=nemo.core.DeviceType.GPU,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\' \\', \\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\', \\'f\\', \\'g\\', \\'h\\', \\'i\\', \\'j\\', \\'k\\', \\'l\\', \\'m\\', \\'n\\', \\'o\\', \\'p\\', \\'q\\', \\'r\\', \\'s\\', \\'t\\', \\'u\\', \\'v\\', \\'w\\', \\'x\\', \\'y\\', \\'z\\', \"\\'\"]'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_CONFIG = '/home/stanislavv/src/tts/NeMo/examples/asr/configs/quartznet15x5.yaml'\n",
    "yaml_loader = yaml.YAML(typ=\"safe\")\n",
    "with open(MODEL_CONFIG) as f:\n",
    "    config = attrdict.AttrDict(yaml_loader.load(f))\n",
    "config.sample_rate = SAMPLE_RATE\n",
    "labels = list(config.labels)\n",
    "str(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AttrDict({'dither': 0.0, 'features': 80, 'frame_splicing': 1, 'highfreq': 8000, 'log': True, 'log_zero_guard_type': 'clamp', 'log_zero_guard_value': 1e-05, 'lowfreq': 0, 'mag_power': 1.0, 'n_fft': 1024, 'n_window_size': 1024, 'n_window_stride': 256, 'normalize': None, 'pad_to': 16, 'pad_value': -11.52, 'preemph': None, 'sample_rate': 24000, 'stft_conv': True, 'window': 'hann', 'window_size': None, 'window_stride': None})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_CONFIG = '/home/stanislavv/src/tts/NeMo/examples/tts/configs/fasterspeech.yaml'\n",
    "yaml_loader = yaml.YAML(typ=\"safe\")\n",
    "with open(MODEL_CONFIG) as f:\n",
    "    pp_config = attrdict.AttrDict(yaml_loader.load(f))\n",
    "pp_config.sample_rate = SAMPLE_RATE\n",
    "pp_config.AudioToMelSpectrogramPreprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-03-25 02:22:00 collections:138] Dataset loaded with 5736 files totalling 8.97 hours\n",
      "[NeMo I 2020-03-25 02:22:00 collections:139] 0 files were filtered totalling 0.00 hours\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AttrDict({'max_duration': None, 'trim_silence': True, 'shuffle': False})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dl_params = copy.deepcopy(config.AudioToTextDataLayer)\n",
    "eval_dl_params.update(config.AudioToTextDataLayer[\"eval\"])\n",
    "del eval_dl_params[\"train\"]\n",
    "del eval_dl_params[\"eval\"]\n",
    "eval_dl_params['shuffle'] = False\n",
    "data_layer = nemo_asr.AudioToTextDataLayer(\n",
    "    manifest_filepath=MAP,\n",
    "    sample_rate=config.sample_rate,\n",
    "    labels=config.labels,\n",
    "    batch_size=64,\n",
    "    **eval_dl_params,\n",
    ")\n",
    "eval_dl_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 508320]), torch.Size([64]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, al, t, tl = next(iter(data_layer._dataloader))\n",
    "a.shape, al.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-03-25 02:22:35 features:144] PADDING: 16\n",
      "[NeMo I 2020-03-25 02:22:35 features:152] STFT using conv\n"
     ]
    }
   ],
   "source": [
    "data_preprocessor = nemo_asr.AudioToMelSpectrogramPreprocessor(\n",
    "    **pp_config.AudioToMelSpectrogramPreprocessor\n",
    ")\n",
    "jasper_encoder = nemo_asr.JasperEncoder(\n",
    "    feat_in=config.AudioToMelSpectrogramPreprocessor[\"features\"], **config.JasperEncoder\n",
    ")\n",
    "jasper_decoder = nemo_asr.JasperDecoderForCTC(\n",
    "    feat_in=config.JasperEncoder[\"jasper\"][-1][\"filters\"], num_classes=len(config.labels)\n",
    ")\n",
    "greedy_decoder = nemo_asr.GreedyCTCDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_signal_e1, a_sig_length_e1, transcript_e1, transcript_len_e1 = data_layer()\n",
    "processed_signal_e1, p_length_e1 = data_preprocessor(input_signal=audio_signal_e1, length=a_sig_length_e1)\n",
    "encoded_e1, encoded_len_e1 = jasper_encoder(audio_signal=processed_signal_e1, length=p_length_e1)\n",
    "log_probs_e1 = jasper_decoder(encoder_output=encoded_e1)\n",
    "predictions_e1 = greedy_decoder(log_probs=log_probs_e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-03-25 02:22:47 actions:1468] Restoring JasperEncoder from /home/stanislavv/data/checkpoints/nemo-quartznet-15x5/JasperEncoder-STEP-406556.pt\n",
      "[NeMo I 2020-03-25 02:22:48 actions:1468] Restoring JasperDecoderForCTC from /home/stanislavv/data/checkpoints/nemo-quartznet-15x5/JasperDecoderForCTC-STEP-406556.pt\n",
      "[NeMo I 2020-03-25 02:22:48 actions:738] Evaluating batch 0 out of 90\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=64, weight of size 64 1 33, expected input[64, 80, 2000] to have 64 channels, but got 80 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-36d227a1cb74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0meval_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlog_probs_e1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions_e1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscript_e1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtranscript_len_e1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_len_e1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_length_e1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mload_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/home/stanislavv/data/checkpoints/nemo-quartznet-15x5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mevaluated_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meval_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mload_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/stanislavv/src/tts/NeMo/nemo/core/neural_factory.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, tensors, checkpoint_dir, ckpt_pattern, verbose, cache, use_cache, offload_to_cpu, modules_to_restore)\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             \u001b[0moffload_to_cpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffload_to_cpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m             \u001b[0mmodules_to_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodules_to_restore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m         )\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stanislavv/src/tts/NeMo/nemo/backends/pytorch/actions.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self, tensors, checkpoint_dir, ckpt_pattern, verbose, cache, use_cache, offload_to_cpu, modules_to_restore)\u001b[0m\n\u001b[1;32m   1493\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1494\u001b[0m             \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1495\u001b[0;31m             \u001b[0moffload_to_cpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moffload_to_cpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1496\u001b[0m         )\n\u001b[1;32m   1497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stanislavv/src/tts/NeMo/nemo/backends/pytorch/actions.py\u001b[0m in \u001b[0;36m_infer\u001b[0;34m(self, tensors_to_return, verbose, cache, use_cache, offload_to_cpu)\u001b[0m\n\u001b[1;32m    763\u001b[0m                     \u001b[0mregistered_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregistered_e_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m                     \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModelMode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 765\u001b[0;31m                     \u001b[0muse_cache\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cache\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    766\u001b[0m                 )\n\u001b[1;32m    767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stanislavv/src/tts/NeMo/nemo/backends/pytorch/actions.py\u001b[0m in \u001b[0;36m__nm_graph_forward_pass\u001b[0;34m(self, call_chain, registered_tensors, mode, use_cache)\u001b[0m\n\u001b[1;32m    426\u001b[0m                 \u001b[0mnew_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcall_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m                 \u001b[0mnew_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforce_pt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcall_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stanislavv/src/tts/NeMo/nemo/backends/pytorch/nm.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, force_pt, *input, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0mpt_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mforce_pt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpt_call\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNeuralModule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stanislavv/Apps/Conda/envs/nemo/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stanislavv/src/tts/NeMo/nemo/collections/asr/jasper.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, audio_signal, length)\u001b[0m\n\u001b[1;32m    180\u001b[0m         \u001b[0;31m# type: (Tensor, Optional[Tensor]) -> Tensor, Optional[Tensor]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0ms_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maudio_signal\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0ms_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stanislavv/Apps/Conda/envs/nemo/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stanislavv/Apps/Conda/envs/nemo/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stanislavv/Apps/Conda/envs/nemo/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stanislavv/src/tts/NeMo/nemo/collections/asr/parts/jasper.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_)\u001b[0m\n\u001b[1;32m    421\u001b[0m             \u001b[0;31m# if (i % 4) == 0 and self.conv_mask:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMaskedConv1d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m                 \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stanislavv/Apps/Conda/envs/nemo/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stanislavv/src/tts/NeMo/nemo/collections/asr/parts/jasper.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lens)\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msh\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheads\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stanislavv/Apps/Conda/envs/nemo/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/stanislavv/Apps/Conda/envs/nemo/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    200\u001b[0m                             _single(0), self.dilation, self.groups)\n\u001b[1;32m    201\u001b[0m         return F.conv1d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 202\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=64, weight of size 64 1 33, expected input[64, 80, 2000] to have 64 channels, but got 80 channels instead"
     ]
    }
   ],
   "source": [
    "eval_tensors = [log_probs_e1, predictions_e1, transcript_e1, transcript_len_e1, encoded_len_e1, p_length_e1]\n",
    "load_dir = '/home/stanislavv/data/checkpoints/nemo-quartznet-15x5'\n",
    "evaluated_tensors = runner.infer(tensors=eval_tensors, checkpoint_dir=load_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04831998074821269"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references = post_process_transcripts(evaluated_tensors[2], evaluated_tensors[3], config.labels)\n",
    "greedy_hypotheses = post_process_predictions(evaluated_tensors[1], config.labels)\n",
    "word_error_rate(greedy_hypotheses, references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = evaluated_tensors[2][0]\n",
    "text_len = evaluated_tensors[3][0]\n",
    "ctc_tokens = evaluated_tensors[1][0]\n",
    "ctc_logprobs = evaluated_tensors[0][0]\n",
    "ctc_len = evaluated_tensors[4][0]\n",
    "mel_len = evaluated_tensors[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = text[0].numpy()\n",
    "text_len1 = text_len[0].numpy().item()\n",
    "ctc_tokens1 = ctc_tokens[0].numpy()\n",
    "ctc_logprobs1 = ctc_logprobs[0].numpy()\n",
    "ctc_len1 = ctc_len[0].numpy().item()\n",
    "mel_len1 = mel_len[0].numpy().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76, 223, (223, 29))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = list(text1[:text_len1])\n",
    "ctc_tokens1 = list(ctc_tokens1[:ctc_len1])\n",
    "ctc_logprobs1 = ctc_logprobs1[:ctc_len1]\n",
    "len(text1), len(ctc_tokens1), ctc_logprobs1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  6,  4, 10,  4,  4,  8,  4,  4,  2, 12,  2,  6,  8,  8,  8,\n",
       "       26,  2,  2,  2,  4,  8,  4,  4,  6,  4,  2,  2,  4,  6,  4,  4,  8,\n",
       "        2,  8,  2,  2,  6,  6,  8,  4,  4,  4,  4,  2,  8,  6,  6,  2, 14,\n",
       "        8,  4,  4, 12,  2,  2,  2,  6,  6,  8,  4,  4, 10,  4,  2,  6,  2,\n",
       "        8,  6, 10,  2,  4,  6,  6,  2,  2, 41])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class PadProcesser:\n",
    "    def __init__(self, labels):\n",
    "        labels = labels + ['~']\n",
    "        self.blank_id = len(labels) - 1\n",
    "        self.space_id = labels.index(' ')\n",
    "        self.labels_map = dict([(i, labels[i]) for i in range(len(labels))])\n",
    "    \n",
    "    def bound_text(self, tokens):\n",
    "        return [self.space_id] + tokens + [self.space_id]\n",
    "    \n",
    "    def bound_ctc(self, tokens, logprobs):\n",
    "        tokens = [self.space_id, self.blank_id] + tokens + [self.blank_id, self.space_id]\n",
    "        \n",
    "        logprobs = np.lib.pad(logprobs, ((2, 2), (0, 0)), 'edge')\n",
    "\n",
    "        def swap(col, a, b):\n",
    "            logprobs[col][a], logprobs[col][b] = logprobs[col][b], logprobs[col][a]\n",
    "        \n",
    "        first_token, last_token = tokens[2], tokens[-3]\n",
    "        swap(0, first_token, self.space_id)\n",
    "        swap(1, first_token, self.blank_id)\n",
    "        swap(-1, last_token, self.space_id)\n",
    "        swap(-2, last_token, self.blank_id)\n",
    "\n",
    "        return tokens, logprobs\n",
    "    \n",
    "    def merge(self, tokens):\n",
    "        output_tokens = []\n",
    "        output_cnts = []\n",
    "        cnt = 0\n",
    "        for i in range(len(tokens)):\n",
    "            if i != 0 and (tokens[i - 1] != tokens[i]):\n",
    "                output_tokens.append(tokens[i - 1])\n",
    "                output_cnts.append(cnt)\n",
    "\n",
    "                cnt = 0\n",
    "\n",
    "            cnt += 1\n",
    "\n",
    "        output_tokens.append(tokens[-1])\n",
    "        output_cnts.append(cnt)\n",
    "        \n",
    "        assert sum(output_cnts) == len(tokens), f'SUM_CHECK {sum(output_cnts)} vs {len(tokens)}'\n",
    "\n",
    "        return output_tokens, output_cnts\n",
    "    \n",
    "    def merge_with_blanks(self, tokens, cnts, logprobs=None):\n",
    "        def choose_sep(l, r, a, b):\n",
    "            # `tokens[l] == a and tokens[r] == b`.\n",
    "            sum_a, sum_b = logprobs[l, a], logprobs[l + 1:r + 1, b].sum()\n",
    "            best_sum, best_sep = sum_a + sum_b, 0\n",
    "            for sep in range(1, r - l):\n",
    "                sum_a += logprobs[l + sep, a]\n",
    "                sum_b -= logprobs[l + sep, b]\n",
    "                if sum_a + sum_b > best_sum:\n",
    "                    best_sum, best_sep = sum_a + sum_b, sep\n",
    "\n",
    "            return best_sep\n",
    "        \n",
    "        output_tokens = []\n",
    "        output_durs = []\n",
    "        blank_cnt = 0\n",
    "        total_cnt = 0\n",
    "        for token, cnt in zip(tokens, cnts):\n",
    "            total_cnt += cnt\n",
    "            if token == self.blank_id:\n",
    "                blank_cnt += cnt\n",
    "                continue\n",
    "            \n",
    "            output_tokens.append(token)\n",
    "            \n",
    "            if logprobs is None:\n",
    "                # Half half.\n",
    "                left_cnt = blank_cnt // 2\n",
    "            else:\n",
    "                # Clever sep choice based on sum of log probs.\n",
    "                left_cnt = choose_sep(\n",
    "                    l=total_cnt - cnt - blank_cnt - 1,\n",
    "                    r=total_cnt - cnt,\n",
    "                    a=output_tokens[-1],\n",
    "                    b=token,\n",
    "                )\n",
    "            right_cnt = blank_cnt - left_cnt\n",
    "            blank_cnt = 0\n",
    "            \n",
    "            if left_cnt:\n",
    "                output_durs[-1] += left_cnt\n",
    "            output_durs.append(cnt + right_cnt)\n",
    "        \n",
    "        output_durs[-1] += blank_cnt\n",
    "\n",
    "        assert sum(output_durs) == sum(cnts), f'SUM_CHECK {sum(output_durs)} vs {sum(cnts)}'\n",
    "\n",
    "        return output_tokens, output_durs\n",
    "    \n",
    "    def align(self, output_tokens, gt_text):\n",
    "        def make_str(tokens):\n",
    "            return ''.join(self.labels_map[c] for c in tokens)\n",
    "        \n",
    "        s = make_str(output_tokens)\n",
    "        t = make_str(gt_text)\n",
    "        alignmet = pairwise2.align.globalxx(s, t)[0]\n",
    "        sa, ta, *_ = alignmet\n",
    "        return sa, ta\n",
    "    \n",
    "    def generate(self, gt_text, alignment, durs):\n",
    "        output_tokens = []\n",
    "        output_cnts = []\n",
    "        si, ti = 0, 0\n",
    "        pairwise2.print_function\n",
    "        for sc, tc in zip(*alignment):\n",
    "            if sc == '-':\n",
    "                output_tokens.append(self.blank_id)\n",
    "                output_cnts.append(2 * durs[si])\n",
    "                si += 1\n",
    "            elif tc == '-':\n",
    "                output_tokens.append(gt_text[ti])\n",
    "                output_cnts.append(0)\n",
    "                ti += 1\n",
    "            else:\n",
    "                output_tokens.append(gt_text[ti])\n",
    "                output_cnts.append(2 * durs[si])\n",
    "                si += 1\n",
    "                ti += 1\n",
    "\n",
    "        assert sum(output_cnts) == 2 * sum(durs)\n",
    "        \n",
    "        return output_tokens, output_cnts\n",
    "\n",
    "    def __call__(self, text, ctc_tokens, ctc_logprobs, mel_len):\n",
    "        # This adds +2 tokens.\n",
    "        text = self.bound_text(text)\n",
    "        # This add +4 tokens, 2 of them are blank.\n",
    "        ctc_tokens, ctc_logprobs = self.bound_ctc(ctc_tokens, ctc_logprobs)\n",
    "\n",
    "        ctc_tokens, ctc_cnts = self.merge(ctc_tokens)\n",
    "        ctc_tokens, ctc_durs = self.merge_with_blanks(ctc_tokens, ctc_cnts, ctc_logprobs)\n",
    "        \n",
    "        alignment = self.align(text, ctc_tokens)\n",
    "        tokens, cnts = self.generate(text, alignment, ctc_durs)\n",
    "        tokens, durs = self.merge_with_blanks(tokens, cnts)\n",
    "        assert tokens == text, 'EXACT_TOKENS_MATCH_CHECK'\n",
    "\n",
    "        def adjust(start, direction, value):\n",
    "            i = start\n",
    "            while value != 0:\n",
    "                dur = durs[i]\n",
    "                \n",
    "                if value < 0:\n",
    "                    durs[i] = dur - value\n",
    "                else:\n",
    "                    durs[i] = max(dur - value, 0)\n",
    "                \n",
    "                value -= dur - durs[i]\n",
    "                i += direction\n",
    "\n",
    "        adjust(0, 1, 4)\n",
    "        adjust(-1, -1, sum(durs) - mel_len)  # Including 4 suffix bound tokens.\n",
    "        assert durs[0] >= 0, f'{durs[0]}'\n",
    "        assert durs[-1] >= 0, f'{durs[-1]}'\n",
    "        \n",
    "        durs = np.array(durs, dtype=np.long)\n",
    "        assert durs.shape[0] == len(text), f'LEN_CHECK {durs.shape[0]} vs {len(text)}'\n",
    "        assert np.sum(durs) == mel_len, f'SUM_CHECK {np.sum(durs)} vs {mel_len}'\n",
    "\n",
    "        return durs\n",
    "\n",
    "processer = PadProcesser(labels)\n",
    "durs1 = processer(text1, ctc_tokens1, ctc_logprobs1, mel_len1)\n",
    "durs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq:\n",
    "    def __init__(self, tokens, cnts=None):\n",
    "        if cnts is None:\n",
    "            cnts = np.ones(len(tokens), dtype=np.long)\n",
    "\n",
    "        assert len(tokens) == len(cnts)\n",
    "        self.tokens = tokens\n",
    "        self.cnts = cnts\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return repr(list(zip(self.tokens, self.cnts)))\n",
    "    \n",
    "    @property\n",
    "    def total(self):\n",
    "        return sum(self.cnts)\n",
    "    \n",
    "    def merge(self):\n",
    "        output_tokens = []\n",
    "        output_cnts = []\n",
    "        \n",
    "        cnt = 0\n",
    "        for i in range(len(self.tokens)):\n",
    "            if i != 0 and (self.tokens[i - 1] != self.tokens[i]):\n",
    "                output_tokens.append(self.tokens[i - 1])\n",
    "                output_cnts.append(cnt)\n",
    "\n",
    "                cnt = 0\n",
    "\n",
    "            cnt += self.cnts[i]\n",
    "\n",
    "        output_tokens.append(self.tokens[-1])\n",
    "        output_cnts.append(cnt)\n",
    "        \n",
    "        assert sum(output_cnts) == sum(self.cnts), \\\n",
    "            f'SUM-CHECK {sum(output_cnts)} vs {sum(self.cnts)}'\n",
    "\n",
    "        return Seq(output_tokens, output_cnts)\n",
    "    \n",
    "    def full_pad(self, blank_id, blank_cnt=1):\n",
    "        output_tokens = [blank_id]\n",
    "        output_cnts = [blank_cnt]\n",
    "\n",
    "        for token, cnt in zip(self.tokens, self.cnts):\n",
    "            output_tokens.append(token)\n",
    "            output_cnts.append(cnt)\n",
    "            \n",
    "            output_tokens.append(blank_id)\n",
    "            output_cnts.append(blank_cnt)\n",
    "        \n",
    "        return Seq(output_tokens, output_cnts)\n",
    "    \n",
    "    def adjust_cnt(self, value, start=-1, direction='left'):\n",
    "        tokens, cnts = self.tokens, self.cnts.copy()\n",
    "        \n",
    "        i, di = start, -1 if direction == 'left' else 1\n",
    "        while value != 0:\n",
    "            cnt = cnts[i]\n",
    "\n",
    "            if value < 0:\n",
    "                cnts[i] = cnt - value\n",
    "            else:\n",
    "                cnts[i] = max(cnt - value, 0)\n",
    "\n",
    "            value -= cnt - cnts[i]\n",
    "            i += di\n",
    "        \n",
    "        return Seq(tokens, cnts)\n",
    "    \n",
    "    def split2(self):\n",
    "        tokens1, cnts1 = [], []\n",
    "        tokens2, cnts2 = [], []\n",
    "        turn = 1\n",
    "        \n",
    "        for token, cnt in zip(self.tokens, self.cnts):\n",
    "            if turn == 1:\n",
    "                tokens1.append(token)\n",
    "                cnts1.append(cnt)\n",
    "            else:\n",
    "                tokens2.append(token)\n",
    "                cnts2.append(cnt)\n",
    "            \n",
    "            turn = 1 if turn == 2 else 2\n",
    "        \n",
    "        return Seq(tokens1, cnts1), Seq(tokens2, cnts2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  2,  4,  6,  2,  0,  2,  0,  4,  0, 10,  0,  4,  6,  6,  0, 22,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4,  2,  2,  2,  0,\n",
       "         0,  4,  0,  2,  4,  4,  2,  0,  0,  0,  0,  0,  4,  4,  0,  8,  6,\n",
       "         6,  0,  2,  0,  0,  0,  2,  4,  6,  0,  2,  6,  2,  0,  0,  0,  6,\n",
       "         4,  8,  0,  0,  0,  0,  2,  0, 41]),\n",
       " array([ 2,  2,  2,  4,  2,  4,  6,  2,  2,  2,  2,  2,  2,  2,  2,  4,  8,\n",
       "         2,  2,  2,  4,  8,  4,  4,  6,  4,  2,  2,  4,  2,  2,  2,  6,  2,\n",
       "         4,  2,  2,  4,  2,  4,  2,  4,  4,  4,  2,  8,  2,  2,  2,  2,  2,\n",
       "         2,  4, 10,  2,  2,  2,  4,  2,  2,  4,  2,  4,  2,  2,  6,  2,  2,\n",
       "         2,  2,  2,  4,  6,  4,  2,  2]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FullProcessor(PadProcesser):\n",
    "    def __call__(self, text, ctc_tokens, ctc_logprobs, mel_len):\n",
    "        text = Seq(text).full_pad(self.blank_id)\n",
    "        ctc = Seq(ctc_tokens).merge().full_pad(self.blank_id, blank_cnt=0).merge()\n",
    "        \n",
    "        alignment = self.align(text.tokens, ctc.tokens)\n",
    "        gen = Seq(*self.generate(text.tokens, alignment, ctc.cnts))\n",
    "        \n",
    "        gen = gen.merge().adjust_cnt(gen.total - mel_len)\n",
    "        \n",
    "        # Two durs conditions.\n",
    "        assert gen.tokens == text.tokens\n",
    "        assert gen.total == mel_len\n",
    "        \n",
    "        blanks, text = gen.split2()\n",
    "        blanks = np.array(blanks.cnts, dtype=np.long)\n",
    "        cnts = np.array(text.cnts, dtype=np.long)\n",
    "        \n",
    "        assert len(blanks) == len(cnts) + 1\n",
    "        \n",
    "        return blanks, cnts\n",
    "\n",
    "\n",
    "processer = FullProcessor(labels)\n",
    "durs1 = processer(text1, ctc_tokens1, ctc_logprobs1, mel_len1)\n",
    "durs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "944.1908576488495"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda: processer(text1, ctc_tokens1, ctc_logprobs1, mel_len1)\n",
    "n, m = 10000, 280000\n",
    "(timeit.timeit(f, number=n) / n) * m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 80/80 [01:52<00:00,  1.41s/it]\n"
     ]
    }
   ],
   "source": [
    "# NOTE: This is going pretty fast.\n",
    "durs_dir = pathlib.Path('/home/stanislavv/data/libri-durs/libritts_original-qn15x5-24k')\n",
    "name = f'{NAME}_full-pad'\n",
    "durs_dir.mkdir(exist_ok=True)\n",
    "# k = -1\n",
    "\n",
    "durs = []\n",
    "for batch in tqdm.tqdm(zip(*evaluated_tensors), total=len(data_layer) // 64):\n",
    "    text = batch[2].numpy()\n",
    "    text_len = batch[3].numpy()\n",
    "    ctc_tokens = batch[1].numpy()\n",
    "    ctc_logprobs = batch[0].numpy()\n",
    "    ctc_len = batch[4].numpy()\n",
    "    mel_len = batch[-1].numpy()\n",
    "\n",
    "    for text1, text_len1, ctc_tokens1, ctc_logprobs1, ctc_len1, mel_len1 in zip(\n",
    "        text, text_len, ctc_tokens, ctc_logprobs, ctc_len, mel_len\n",
    "    ):\n",
    "        text1 = list(text1[:text_len1])\n",
    "        ctc_tokens1 = list(ctc_tokens1[:ctc_len1])\n",
    "        ctc_logprobs1 = ctc_logprobs1[:ctc_len1]\n",
    "        mel_len1 = mel_len1.item()\n",
    "\n",
    "        durs1 = processer(text1, ctc_tokens1, ctc_logprobs1, mel_len1)\n",
    "\n",
    "#         k += 1\n",
    "#         np.save(durs_dir / f'{k}.npy', durs1, allow_pickle=False)\n",
    "        \n",
    "        durs.append(durs1)\n",
    "\n",
    "\n",
    "np.save(durs_dir / f'{name}.npy', durs, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  14,   15,   16,   17,   18,   19,   20,   21,   22,   23,   24,\n",
       "         25,   26,   27,   28,   29,   30,   31,   32,   33,   34,   35,\n",
       "         36,   37,   38,   39,   40,   41,   42,   43,   44,   45,   46,\n",
       "         47,   48,   49,   50,   51,   52,   53,   54,   55,   56,   57,\n",
       "         58,   59,   60,   61,   62,   63,   64,   65,   66,   67,   68,\n",
       "         69,   70,   71,   72,   73,   74,   75,   76,   77,   78,   79,\n",
       "         80,   81,   82,   83,   84,   85,   86,   87,   88,   89,   90,\n",
       "         91,   92,   93,   94,   95,   96,   97,   98,   99,  100,  101,\n",
       "        102,  103,  104,  105,  106,  107,  108,  109,  110,  111,  112,\n",
       "        113,  114,  116,  117,  118,  120,  122,  124,  126,  128,  130,\n",
       "        131,  132,  134,  136,  138,  140,  142,  144,  146,  148,  150,\n",
       "        152,  154,  156,  158,  160,  162,  164,  166,  168,  170,  172,\n",
       "        174,  176,  178,  180,  182,  184,  186,  188,  190,  192,  194,\n",
       "        196,  198,  200,  202,  204,  206,  208,  210,  212,  214,  216,\n",
       "        218,  220,  222,  224,  226,  228,  230,  232,  234,  236,  238,\n",
       "        240,  242,  244,  246,  248,  250,  252,  254,  256,  258,  260,\n",
       "        262,  264,  266,  268,  270,  272,  274,  276,  278,  280,  282,\n",
       "        284,  286,  288,  290,  292,  294,  296,  298,  300,  302,  304,\n",
       "        306,  308,  310,  312,  314,  316,  318,  320,  322,  324,  326,\n",
       "        328,  330,  332,  334,  336,  338,  340,  342,  344,  346,  348,\n",
       "        350,  352,  354,  356,  358,  360,  362,  364,  366,  368,  370,\n",
       "        372,  374,  376,  378,  380,  382,  384,  386,  388,  390,  392,\n",
       "        394,  396,  398,  400,  402,  404,  406,  408,  410,  412,  414,\n",
       "        416,  418,  420,  422,  424,  426,  428,  430,  432,  436,  438,\n",
       "        440,  442,  446,  448,  452,  454,  456,  458,  460,  462,  464,\n",
       "        466,  470,  472,  474,  476,  482,  484,  488,  490,  492,  494,\n",
       "        502,  508,  510,  512,  514,  518,  522,  524,  526,  534,  538,\n",
       "        540,  554,  558,  568,  586,  590,  592,  602,  630,  644,  652,\n",
       "        666,  670,  676,  684,  760,  816,  840, 1130])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(max_blanks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1130"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(b.max() for b, _ in durs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(d.max() for _, d in durs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1167549, 49408497, 2.363053059476794)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num, total = 0, 0\n",
    "for b, _ in durs:\n",
    "    num += (b > 30).sum()\n",
    "    total += len(b)\n",
    "\n",
    "num, total, (num / total * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31619, 49129870, 0.06435799646935765)"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num, total = 0, 0\n",
    "for _, d in durs:\n",
    "    num += (d > 15).sum()\n",
    "    total += len(d)\n",
    "\n",
    "num, total, (num / total * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/278627 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 14127/278627 [00:00<00:01, 141258.35it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 26700/278627 [00:00<00:01, 136209.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 36747/278627 [00:00<00:01, 123074.31it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 49495/278627 [00:00<00:01, 124361.40it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 62138/278627 [00:00<00:01, 124971.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 74744/278627 [00:00<00:01, 125295.71it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███▏      | 87506/278627 [00:00<00:01, 125982.50it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 100505/278627 [00:00<00:01, 127157.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 113237/278627 [00:00<00:01, 127205.44it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 125793/278627 [00:01<00:01, 126704.68it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 138547/278627 [00:01<00:01, 126951.90it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 151085/278627 [00:01<00:01, 126474.15it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▊    | 163550/278627 [00:01<00:00, 125234.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 175949/278627 [00:01<00:00, 123761.67it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 188242/278627 [00:01<00:00, 122351.37it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 200423/278627 [00:01<00:00, 121550.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 212541/278627 [00:01<00:00, 120701.26it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 224767/278627 [00:01<00:00, 121163.18it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 237060/278627 [00:01<00:00, 121684.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 249378/278627 [00:02<00:00, 122127.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 261584/278627 [00:02<00:00, 121933.34it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 278627/278627 [00:02<00:00, 123477.48it/s]\u001b[A\u001b[A\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(\n",
    "    list(itertools.chain.from_iterable(b for b, _ in tqdm.tqdm(durs))),\n",
    "    bins=range(20),\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
