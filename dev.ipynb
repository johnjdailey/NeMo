{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import nemo\n",
    "import copy\n",
    "import tqdm\n",
    "import timeit\n",
    "import shutil\n",
    "import pathlib\n",
    "import attrdict\n",
    "import numpy as np\n",
    "\n",
    "from ruamel import yaml\n",
    "from Bio import pairwise2\n",
    "from nemo.collections import asr as nemo_asr\n",
    "from nemo.collections.asr.helpers import post_process_predictions, post_process_transcripts, word_error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGC_MAP = '~/Downloads/librivox-train-all.json'\n",
    "LOCAL_MAP = [\n",
    "    '/home/stanislavv/data/nemo-librispeech/train_clean_100.json',\n",
    "    '/home/stanislavv/data/nemo-librispeech/train_clean_360.json',\n",
    "    '/home/stanislavv/data/nemo-librispeech/train_other_500.json',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['792-127528-0000',\n",
       " '792-127528-0001',\n",
       " '792-127528-0002',\n",
       " '792-127528-0003',\n",
       " '792-127528-0004']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_ngc_id(audio_file):\n",
    "    return os.path.basename(audio_file)[:-4]\n",
    "\n",
    "\n",
    "order = [\n",
    "    get_ngc_id(example['audio_file']) \n",
    "    for example in nemo.collections.asr.parts.manifest.item_iter(NGC_MAP)\n",
    "]\n",
    "order[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1594-135914-0000', 0),\n",
       " ('1594-135914-0001', 1),\n",
       " ('1594-135914-0002', 2),\n",
       " ('1594-135914-0003', 3),\n",
       " ('1594-135914-0004', 4)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_id_index = [\n",
    "    (get_ngc_id(example['audio_file']), i)\n",
    "    for i, example in enumerate(nemo.collections.asr.parts.manifest.item_iter(LOCAL_MAP))\n",
    "]\n",
    "local_id_index[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[133099, 133100, 133101, 133102, 133103]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local_id_index_dict = dict(local_id_index)\n",
    "new_order = [local_id_index_dict[id_] for id_ in order]\n",
    "new_order[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "AD_HOC_MAP = '/home/stanislavv/data/nemo-librispeech/train-all.json'\n",
    "\n",
    "lines = []\n",
    "for mf in LOCAL_MAP:\n",
    "    with open(mf, 'r') as f:\n",
    "        lines.extend(list(f))\n",
    "lines = [lines[id_] for id_ in new_order]\n",
    "\n",
    "with open(AD_HOC_MAP, 'w') as f:\n",
    "    for line in lines:\n",
    "        f.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2020-03-13 14:51:14 deprecated:68] Function ``_get_trainer`` is deprecated. It is going to be removed in the future version.\n"
     ]
    }
   ],
   "source": [
    "runner = nemo.core.NeuralModuleFactory(\n",
    "    placement=nemo.core.DeviceType.GPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[\\' \\', \\'a\\', \\'b\\', \\'c\\', \\'d\\', \\'e\\', \\'f\\', \\'g\\', \\'h\\', \\'i\\', \\'j\\', \\'k\\', \\'l\\', \\'m\\', \\'n\\', \\'o\\', \\'p\\', \\'q\\', \\'r\\', \\'s\\', \\'t\\', \\'u\\', \\'v\\', \\'w\\', \\'x\\', \\'y\\', \\'z\\', \"\\'\"]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODEL_CONFIG = 'examples/asr/configs/quartznet15x5.yaml'\n",
    "yaml_loader = yaml.YAML(typ=\"safe\")\n",
    "with open(MODEL_CONFIG) as f:\n",
    "    config = attrdict.AttrDict(yaml_loader.load(f))\n",
    "labels = list(config.labels)\n",
    "str(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-03-13 14:52:31 collections:138] Dataset loaded with 278627 files totalling 948.67 hours\n",
      "[NeMo I 2020-03-13 14:52:31 collections:139] 2614 files were filtered totalling 12.38 hours\n"
     ]
    }
   ],
   "source": [
    "eval_dl_params = copy.deepcopy(config.AudioToTextDataLayer)\n",
    "eval_dl_params.update(config.AudioToTextDataLayer[\"train\"])\n",
    "del eval_dl_params[\"train\"]\n",
    "del eval_dl_params[\"eval\"]\n",
    "eval_dl_params['shuffle'] = False\n",
    "data_layer = nemo_asr.AudioToTextDataLayer(\n",
    "    manifest_filepath=AD_HOC_MAP,\n",
    "    sample_rate=config.sample_rate,\n",
    "    labels=config.labels,\n",
    "    batch_size=32,\n",
    "    **eval_dl_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-03-13 14:52:31 features:144] PADDING: 16\n",
      "[NeMo I 2020-03-13 14:52:31 features:152] STFT using conv\n"
     ]
    }
   ],
   "source": [
    "data_preprocessor = nemo_asr.AudioToMelSpectrogramPreprocessor(\n",
    "    sample_rate=config.sample_rate, **config.AudioToMelSpectrogramPreprocessor\n",
    ")\n",
    "jasper_encoder = nemo_asr.JasperEncoder(\n",
    "    feat_in=config.AudioToMelSpectrogramPreprocessor[\"features\"], **config.JasperEncoder\n",
    ")\n",
    "jasper_decoder = nemo_asr.JasperDecoderForCTC(\n",
    "    feat_in=config.JasperEncoder[\"jasper\"][-1][\"filters\"], num_classes=len(config.labels)\n",
    ")\n",
    "greedy_decoder = nemo_asr.GreedyCTCDecoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_signal_e1, a_sig_length_e1, transcript_e1, transcript_len_e1 = data_layer()\n",
    "processed_signal_e1, p_length_e1 = data_preprocessor(input_signal=audio_signal_e1, length=a_sig_length_e1)\n",
    "encoded_e1, encoded_len_e1 = jasper_encoder(audio_signal=processed_signal_e1, length=p_length_e1)\n",
    "log_probs_e1 = jasper_decoder(encoder_output=encoded_e1)\n",
    "predictions_e1 = greedy_decoder(log_probs=log_probs_e1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2020-03-13 14:52:35 actions:1459] Restoring JasperEncoder from /home/stanislavv/data/nemo-quartznet-15x5/JasperEncoder-STEP-406556.pt\n",
      "[NeMo I 2020-03-13 14:52:36 actions:1459] Restoring JasperDecoderForCTC from /home/stanislavv/data/nemo-quartznet-15x5/JasperDecoderForCTC-STEP-406556.pt\n",
      "[NeMo I 2020-03-13 14:52:36 actions:729] Evaluating batch 0 out of 8708\n",
      "[NeMo I 2020-03-13 14:57:31 actions:729] Evaluating batch 870 out of 8708\n",
      "[NeMo I 2020-03-13 15:02:28 actions:729] Evaluating batch 1740 out of 8708\n",
      "[NeMo I 2020-03-13 15:07:25 actions:729] Evaluating batch 2610 out of 8708\n",
      "[NeMo I 2020-03-13 15:12:23 actions:729] Evaluating batch 3480 out of 8708\n",
      "[NeMo I 2020-03-13 15:17:20 actions:729] Evaluating batch 4350 out of 8708\n",
      "[NeMo I 2020-03-13 15:22:20 actions:729] Evaluating batch 5220 out of 8708\n",
      "[NeMo I 2020-03-13 15:27:19 actions:729] Evaluating batch 6090 out of 8708\n",
      "[NeMo I 2020-03-13 15:32:18 actions:729] Evaluating batch 6960 out of 8708\n",
      "[NeMo I 2020-03-13 15:37:17 actions:729] Evaluating batch 7830 out of 8708\n",
      "[NeMo I 2020-03-13 15:42:17 actions:729] Evaluating batch 8700 out of 8708\n"
     ]
    }
   ],
   "source": [
    "eval_tensors = [log_probs_e1, predictions_e1, transcript_e1, transcript_len_e1, encoded_len_e1, p_length_e1]\n",
    "load_dir = '/home/stanislavv/data/nemo-quartznet-15x5'\n",
    "evaluated_tensors = runner.infer(tensors=eval_tensors, checkpoint_dir=load_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0049496181304478715"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "references = post_process_transcripts(evaluated_tensors[2], evaluated_tensors[3], config.labels)\n",
    "greedy_hypotheses = post_process_predictions(evaluated_tensors[1], config.labels)\n",
    "word_error_rate(greedy_hypotheses, references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = evaluated_tensors[2][0]\n",
    "text_len = evaluated_tensors[3][0]\n",
    "ctc_tokens = evaluated_tensors[1][0]\n",
    "ctc_logprobs = evaluated_tensors[0][0]\n",
    "ctc_len = evaluated_tensors[4][0]\n",
    "mel_len = evaluated_tensors[-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = text[0].numpy()\n",
    "text_len1 = text_len[0].numpy().item()\n",
    "ctc_tokens1 = ctc_tokens[0].numpy()\n",
    "ctc_logprobs1 = ctc_logprobs[0].numpy()\n",
    "ctc_len1 = ctc_len[0].numpy().item()\n",
    "mel_len1 = mel_len[0].numpy().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(174, 810, (810, 29))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1 = list(text1[:text_len1])\n",
    "ctc_tokens1 = list(ctc_tokens1[:ctc_len1])\n",
    "ctc_logprobs1 = ctc_logprobs1[:ctc_len1]\n",
    "len(text1), len(ctc_tokens1), ctc_logprobs1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  38,   8,   2,  10,   6,   4,   4,   4,  14,  16,   2,   8,\n",
       "         6,   2,  12,   4, 294,   8,   8,   4,   4,   8,   6,   6,   6,\n",
       "         2,   4,   4,  58,   4,   2,   2,   2,   4,   4,   2,   2,   2,\n",
       "         4,   4,   4,   2,   4,  12,   4,   8,   4,  10,   4,   6,   4,\n",
       "         8,   8,   4,   4,   4,  16,   4,   4,   4,   8,   2,   2,   2,\n",
       "         8,   6,   2,   8,   2,  10,  12,   6,   6,  72,   4,   2,   6,\n",
       "         6,   2,   2,   6,   4,   2,   2,   2,   8,   4,   8,   8,  10,\n",
       "         2,   2,   6,   2,   6,   6,   2,   4,   8,   4,   8,  10,   2,\n",
       "         6,   8,  40,  28,   4,   4,   2,   8,   6,   6,   4,   2,   2,\n",
       "        52,   8,   6,  12,   6,   4,   2,   6,   6,   4,   6,  10,   6,\n",
       "         2,   8,   6,   2,  10,   2,   2,   2,   4,  12,   6,   6,   2,\n",
       "         8,   6,   4,  10,   4,   2,   2,  16,   6,   2,  46,  18,   8,\n",
       "         4,   6,   4,   2,   8,   2,   4,   8,   4,   4,   4,   8,   8,\n",
       "        10,   4,   6,  10,   6,  84,   3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Processer:\n",
    "    def __init__(self, labels):\n",
    "        labels = labels + ['<BLANK>']\n",
    "        self.space_id = labels.index(' ')\n",
    "        self.blank_id = len(labels) - 1\n",
    "        self.labels_map = dict([(i, labels[i]) for i in range(len(labels))])\n",
    "    \n",
    "    def bound_text(self, tokens):\n",
    "        return [self.space_id] + tokens + [self.space_id]\n",
    "    \n",
    "    def bound_ctc(self, tokens, logprobs):\n",
    "        tokens = [self.space_id, self.blank_id] + tokens + [self.blank_id, self.space_id]\n",
    "        \n",
    "        logprobs = np.lib.pad(logprobs, ((2, 2), (0, 0)), 'edge')\n",
    "\n",
    "        def swap(col, a, b):\n",
    "            logprobs[col][a], logprobs[col][b] = logprobs[col][b], logprobs[col][a]\n",
    "        \n",
    "        first_token, last_token = tokens[2], tokens[-3]\n",
    "        swap(0, first_token, self.space_id)\n",
    "        swap(1, first_token, self.blank_id)\n",
    "        swap(-1, last_token, self.space_id)\n",
    "        swap(-2, last_token, self.blank_id)\n",
    "\n",
    "        return tokens, logprobs\n",
    "    \n",
    "    def merge(self, tokens):\n",
    "        output_tokens = []\n",
    "        output_cnts = []\n",
    "        cnt = 0\n",
    "        for i in range(len(tokens)):\n",
    "            if i != 0 and (tokens[i - 1] != tokens[i]):\n",
    "                output_tokens.append(tokens[i - 1])\n",
    "                output_cnts.append(cnt)\n",
    "\n",
    "                cnt = 0\n",
    "\n",
    "            cnt += 1\n",
    "\n",
    "        output_tokens.append(tokens[-1])\n",
    "        output_cnts.append(cnt)\n",
    "        \n",
    "        assert sum(output_cnts) == len(tokens), f'SUM_CHECK {sum(output_cnts)} vs {len(tokens)}'\n",
    "\n",
    "        return output_tokens, output_cnts\n",
    "    \n",
    "    def merge_with_blanks(self, tokens, cnts, logprobs=None):\n",
    "        def choose_sep(l, r, a, b):\n",
    "            # `tokens[l] == a and tokens[r] == b`.\n",
    "            sum_a, sum_b = logprobs[l, a], logprobs[l + 1:r + 1, b].sum()\n",
    "            best_sum, best_sep = sum_a + sum_b, 0\n",
    "            for sep in range(1, r - l):\n",
    "                sum_a += logprobs[l + sep, a]\n",
    "                sum_b -= logprobs[l + sep, b]\n",
    "                if sum_a + sum_b > best_sum:\n",
    "                    best_sum, best_sep = sum_a + sum_b, sep\n",
    "\n",
    "            return best_sep\n",
    "        \n",
    "        output_tokens = []\n",
    "        output_durs = []\n",
    "        blank_cnt = 0\n",
    "        total_cnt = 0\n",
    "        for token, cnt in zip(tokens, cnts):\n",
    "            total_cnt += cnt\n",
    "            if token == self.blank_id:\n",
    "                blank_cnt += cnt\n",
    "                continue\n",
    "            \n",
    "            output_tokens.append(token)\n",
    "            \n",
    "            if logprobs is None:\n",
    "                # Half half.\n",
    "                left_cnt = blank_cnt // 2\n",
    "            else:\n",
    "                # Clever sep choice based on sum of log probs.\n",
    "                left_cnt = choose_sep(\n",
    "                    l=total_cnt - cnt - blank_cnt - 1,\n",
    "                    r=total_cnt - cnt,\n",
    "                    a=output_tokens[-1],\n",
    "                    b=token,\n",
    "                )\n",
    "            right_cnt = blank_cnt - left_cnt\n",
    "            blank_cnt = 0\n",
    "            \n",
    "            if left_cnt:\n",
    "                output_durs[-1] += left_cnt\n",
    "            output_durs.append(cnt + right_cnt)\n",
    "        \n",
    "        output_durs[-1] += blank_cnt\n",
    "\n",
    "        assert sum(output_durs) == sum(cnts), f'SUM_CHECK {sum(output_durs)} vs {sum(cnts)}'\n",
    "\n",
    "        return output_tokens, output_durs\n",
    "    \n",
    "    def align(self, output_tokens, gt_text):\n",
    "        def make_str(tokens):\n",
    "            return ''.join(self.labels_map[c] for c in tokens)\n",
    "        \n",
    "        s = make_str(output_tokens)\n",
    "        t = make_str(gt_text)\n",
    "        alignmet = pairwise2.align.globalxx(s, t)[0]\n",
    "        sa, ta, *_ = alignmet\n",
    "        return sa, ta\n",
    "    \n",
    "    def generate(self, gt_text, alignment, durs):\n",
    "        output_tokens = []\n",
    "        output_cnts = []\n",
    "        si, ti = 0, 0    \n",
    "        for sc, tc in zip(*alignment):\n",
    "            if sc == '-':\n",
    "                output_tokens.append(self.blank_id)\n",
    "                output_cnts.append(2 * durs[si])\n",
    "                si += 1\n",
    "            elif tc == '-':\n",
    "                output_tokens.append(gt_text[ti])\n",
    "                output_cnts.append(0)\n",
    "                ti += 1\n",
    "            else:\n",
    "                output_tokens.append(gt_text[ti])\n",
    "                output_cnts.append(2 * durs[si])\n",
    "                si += 1\n",
    "                ti += 1\n",
    "\n",
    "        assert sum(output_cnts) == 2 * sum(durs)\n",
    "        \n",
    "        return output_tokens, output_cnts\n",
    "\n",
    "    def __call__(self, text, ctc_tokens, ctc_logprobs, mel_len):\n",
    "        # This adds +2 tokens.\n",
    "        text = self.bound_text(text)\n",
    "        # This add +4 tokens, 2 of them are blank.\n",
    "        ctc_tokens, ctc_logprobs = self.bound_ctc(ctc_tokens, ctc_logprobs)\n",
    "\n",
    "        ctc_tokens, ctc_cnts = self.merge(ctc_tokens)\n",
    "        ctc_tokens, ctc_durs = self.merge_with_blanks(ctc_tokens, ctc_cnts, ctc_logprobs)\n",
    "        \n",
    "        alignment = self.align(text, ctc_tokens)\n",
    "        tokens, cnts = self.generate(text, alignment, ctc_durs)\n",
    "        tokens, durs = self.merge_with_blanks(tokens, cnts)\n",
    "        assert tokens == text, 'EXACT_TOKENS_MATCH_CHECK'\n",
    "\n",
    "        def adjust(start, direction, value):\n",
    "            i = start\n",
    "            while value != 0:\n",
    "                dur = durs[i]\n",
    "                \n",
    "                if value < 0:\n",
    "                    durs[i] = dur - value\n",
    "                else:\n",
    "                    durs[i] = max(dur - value, 0)\n",
    "                \n",
    "                value -= dur - durs[i]\n",
    "                i += direction\n",
    "\n",
    "        adjust(0, 1, 4)\n",
    "        adjust(-1, -1, sum(durs) - mel_len)  # Including 4 suffix bound tokens.\n",
    "        assert durs[0] >= 0, f'{durs[0]}'\n",
    "        assert durs[-1] >= 0, f'{durs[-1]}'\n",
    "        \n",
    "        durs = np.array(durs, dtype=np.long)\n",
    "        assert durs.shape[0] == len(text), f'LEN_CHECK {durs.shape[0]} vs {len(text)}'\n",
    "        assert np.sum(durs) == mel_len, f'SUM_CHECK {np.sum(durs)} vs {mel_len}'\n",
    "\n",
    "        return durs\n",
    "\n",
    "processer = Processer(labels)\n",
    "durs1 = processer(text1, ctc_tokens1, ctc_logprobs1, mel_len1)\n",
    "durs1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "944.1908576488495"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = lambda: processer(text1, ctc_tokens1, ctc_logprobs1, mel_len1)\n",
    "n, m = 10000, 280000\n",
    "(timeit.timeit(f, number=n) / n) * m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 8708/8789 [18:02<00:10,  8.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# NOTE: This is going pretty fast.\n",
    "durs_dir = pathlib.Path('/home/stanislavv/data/nemo-librispeech/durs')\n",
    "durs_dir.mkdir(exist_ok=True)\n",
    "k = -1\n",
    "\n",
    "for batch in tqdm.tqdm(zip(*evaluated_tensors), total=8789):\n",
    "    text = batch[2].numpy()\n",
    "    text_len = batch[3].numpy()\n",
    "    ctc_tokens = batch[1].numpy()\n",
    "    ctc_logprobs = batch[0].numpy()\n",
    "    ctc_len = batch[4].numpy()\n",
    "    mel_len = batch[-1].numpy()\n",
    "\n",
    "    for text1, text_len1, ctc_tokens1, ctc_logprobs1, ctc_len1, mel_len1 in zip(\n",
    "        text, text_len, ctc_tokens, ctc_logprobs, ctc_len, mel_len\n",
    "    ):\n",
    "        text1 = list(text1[:text_len1])\n",
    "        ctc_tokens1 = list(ctc_tokens1[:ctc_len1])\n",
    "        ctc_logprobs1 = ctc_logprobs1[:ctc_len1]\n",
    "        mel_len1 = mel_len1.item()\n",
    "\n",
    "        durs1 = processer(text1, ctc_tokens1, ctc_logprobs1, mel_len1)\n",
    "\n",
    "        k += 1\n",
    "        np.save(durs_dir / f'{k}.npy', durs1, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 278627/278627 [01:09<00:00, 3999.21it/s]\n"
     ]
    }
   ],
   "source": [
    "durs_dir = pathlib.Path('/home/stanislavv/data/nemo-librispeech/durs')\n",
    "arrays = []\n",
    "for index in tqdm.trange(278627):\n",
    "    arrays.append(np.load(durs_dir / f'{index}.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278627"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/stanislavv/data/nemo-librispeech/all-durs.npy', arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrays = np.load('/home/stanislavv/data/nemo-librispeech/bigdurs.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  38,   8,   2,  10,   6,   4,   4,   4,  14,  16,   2,   8,\n",
       "         6,   2,  12,   4, 294,   8,   8,   4,   4,   8,   6,   6,   6,\n",
       "         2,   4,   4,  58,   4,   2,   2,   2,   4,   4,   2,   2,   2,\n",
       "         4,   4,   4,   2,   4,  12,   4,   8,   4,  10,   4,   6,   4,\n",
       "         8,   8,   4,   4,   4,  16,   4,   4,   4,   8,   2,   2,   2,\n",
       "         8,   6,   2,   8,   2,  10,  12,   6,   6,  72,   4,   2,   6,\n",
       "         6,   2,   2,   6,   4,   2,   2,   2,   8,   4,   8,   8,  10,\n",
       "         2,   2,   6,   2,   6,   6,   2,   4,   8,   4,   8,  10,   2,\n",
       "         6,   8,  40,  28,   4,   4,   2,   8,   6,   6,   4,   2,   2,\n",
       "        52,   8,   6,  12,   6,   4,   2,   6,   6,   4,   6,  10,   6,\n",
       "         2,   8,   6,   2,  10,   2,   2,   2,   4,  12,   6,   6,   2,\n",
       "         8,   6,   4,  10,   4,   2,   2,  16,   6,   2,  46,  18,   8,\n",
       "         4,   6,   4,   2,   8,   2,   4,   8,   4,   4,   4,   8,   8,\n",
       "        10,   4,   6,  10,   6,  84,   3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrays[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "278627"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(durs_dir.iterdir()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
